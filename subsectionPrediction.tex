\subsection{Prediction Model}

\subsection{Cost Aware Scaling}
Most of the public PaaS solutions like Google App Engine provide SLAs based on the QoS provided. According these SLAs, a penalty will be charged from the provider to the PaaS user in a case where the provider was unable to provide the agreed level of service. In most cases this penalty is defined as a percentage of the monthly cost of users.

We propose a greedy heuristic scaling algorithm inspired by already existing PaaS SLAs. However, unlike most PaaS providers, we do not consider service uptime as the measure of QoS. Instead we consider any performance degradation with respect to the matrix considered (Memory Consumption, CPU, Requests in Flight) as a violation.

\subsubsection{Scaling Algorithm}
Considering both resource cost and the penalty for performance degradation, we define the total cost in the next T minutes as follows.\\
$ C_t = C_{ins} \times n { + } C_{ins} \times n \times f(v_i \times \frac{100}{T}) $ \\
\\
$ T $       = Total time for prediction \\
$ C_t $     = Total cost for time T  \\
$ C_{ins} $ = Cost for an instance   \\
$ n $       = Number of instances  \\
$ v_i $     = Violation time  \\

Using the above definition, we calculate the total cost for different numbers of instances, n. Increasing the number of instances increases resource cost but decreases penalty factor (and therefore the violation cost). Considering values from the minimum number of VMs to the maximum number of VMs allowed, we decide an optimum number that minimizes the total cost. Such an exhaustive search is made possible by the bounded and relatively small range of VM count in most set-ups.
\subsubsection {Pricing Model Awareness}

Our proposed solution also considers the pricing model of the underlying IaaS layer when taking auto scaling decisions. We adapted the smart killing feature proposed in [\cite{pluggable}] after evaluating the concept. Cloud providers like AWS bill customers on a per-hour basis, which means a user will be charged for one hour even if an instance is used only for a few minutes. Smart killing suggests that an instance should not be spin downed if it has not completed a full billing cycle. Considering practical issues such as the time required to gracefully shut down an instance, we spin down an instance only if it used for 50 to 57 minutes in its billing hour. However, smart killing is only useful for IaaS models with relatively long billing cycles.

\subsubsection{Simulation Results}
First two graphs in the Figure 3 shows the variation of instance count with and without smart killing when the prediction mechanism of Stratos is used, along with an 80\% threshold value to calculate the required number of instances.

Last four graphs at bottom in figure 3 shows possible combinations of reactive and proactive auto scaling approaches with and without smart killing. An 80\% threshold level is used in reactive solutions as well. In the proactive approach, the proposed heuristic is used with following penalty function:

f(x) = 0.1    0.05 < x <=1 \\
f(x) = 0.2    1 < x <= 5 \\
f(x) = 2^(x/20)    5 < x <= 100 

From the results shown (in Fig 3 and Fig 4), we conclude that implementing smart killing on auto scaling solutions improves resource utilization while reducing the cost significantly in most cases, regardless of the auto scaling approach (reactive or proactive). We also conclude the proposed proactive scaling approach outperforms the reactive threshold approach, considering QoS as well as resource cost.

\subsubsection{Suggested Improvements}

It is possible to improve the proposed heuristic by introducing different penalty functions  based on the level of service expected by different users. For example, an application (deployed on a PaaS) that supports free as well as paid versions would require different service levels. Our proposed solution can be adapted for such scenarios by defining different penalty functions based on the type of subscription.

\subsection{Execution Engine}