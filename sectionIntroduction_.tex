\section{Introduction}
Cloud systems rely on virtualization techniques to provide computing resources on demand. Scalability is a key feature where provisioning and de-provisioning of resources are done via auto-scaling. At the platform-as-a-service (PaaS) level, auto-scaling mainly deals with infrastructure resource management and cost saving for the customer. Although meeting High Availability (HA) and other QoS parameters is important, the user also desires to consume just the right amount of resources necessary to satisfy the performance requirement of the application. Currently in most of the PaaS auto scalers, scaling decisions are based on a rule engine which is inadequate for predicting workload or learning application characteristics, and also inefficient in resource allocation. \\

We take a novel perspective in addressing this problem where the infrastructure-as-a-service (IaaS) providers expose their resource specifications and pricing schemes. Assuming such a scenario, we propose an intelligent auto scaler which comprises of a cost model, prediction model and smart killing feature. The cost model evaluates all possibilities and selects the optimum resource configuration considering the lease cost and Service Level Agreement (SLA) violation cost. The prediction model is an ensemble system with a time series model and a machine learning model to best fit the prediction based on workload characteristics of the application. Smart Kiling feature overcomes naive resource allocation by considering the constraints of the underlying IaaS vendor. \\

One of the major drawback in a rule based auto scaler is that the user is expected to be a domain expert and should be aware of the threshold values such as memory usage and CPU consumption for his application in order for configuring policies or rules to govern the scaling decisions.\cite{modeldriven} On the other hand, mapping application metrics such as response time and transactions per unit time to system level metrics such as CPU usage and disk IO rates is a research level problem, which an average user cannot comprehend. In our solution we mitigate the problem of comprehending a threshold value by forecasting the workload ahead so the auto-scaler can decide at which point the resources should be scaled out or scaled in, looking at the future workload instead of waiting for a trigger.\\

Another major drawback of a typical PaaS auto scaler is the ignorance of the cost factor in making a scaling decision. For a motivation example let us consider a typical application deployed on top of Amazon Web Service (AWS) PaaS. On a sudden fluctuation in the workload, a typical auto scaler would scale-out to spin up a new VM instance and when the workload is back to normal the auto-scaler would scale-in by blindly killing one of the VM instances which has already been paid for for an hour. Thus the customer has lost a 50 minutes utilization of the instance. Smart Killing feature would apprehend the utilization of each VM instance and scale out instances only when their lease periods are about to expire. It would also save an extra cost by mitigating the requirement to spin up another instance on a sudden fluctuation of the workload within the paid hour.\\

In an attempt to implement our solution and demonstrate the effects of a PaaS auto-scaler, we target Apache Stratos PaaS; however, the techniques detailed here are extensible to other PaaS systems as well. Apache Stratos, an open source PaaS framework offering multi-tenancy and multi-cloud deployment capabilities by encapsulating the details to the level of reduced granularity and complexity of a PaaS. Stratos supports multiple IaaS providers, including AWS, OpenStack, GCE (Google Compute Engine) and Microsoft Azure\cite{website:stratos}. Stratos auto scaler is based on policy-driven  decisions, which performs workload prediction for a small time window (usually a few minutes) but does not utilize resource optimization approaches explicitly, thereby incurring unnecessary costs to the customer, such as overprovisioning of resources and naive scale down decisions. Apart from the typical characteristics of a PaaS auto scaler, Stratos offer other features such as a modular architecture allowing easy modifications, and the availability of a mock IaaS as a component for testing and evaluation, which would greatly assist any research in terms of monetary cost and implementation cost.\\

We evaluate inteliScaler by deploying  Apache Stratos on AWS Elastic Cloud Computing(EC2). We deploy the three-tier bidding benchmark RUBiS as the user application and experiment with various workload traces. Our results demonstrate that inteliScaler successfully scales the application in response to fluctuating workloads, without user intervention and without offline profiling. More importantly, we compare our solution with existing rule based triggers and show that inteliScaler is superior to such approaches.\\

We begin by discussing prior work and detailing our approach towards an intelligent auto scaler and its implementation within Apache Stratos PaaS. Then we evaluate each component of our auto scaler individually and discuss various techniques we used for each. Finally, we demonstrate the effectiveness of our approach using a simulation and an experimental setup on AWS. \\