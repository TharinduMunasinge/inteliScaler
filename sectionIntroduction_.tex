\section{Introduction}
Autoscaling is the process of dynamically allocating and deallocating resources for particular application deployed in the cloud. This is of vital importance for clients to optimize their resource utilization.  Goal of an cloud auto scaling mechanisms (autoscalers) try to achieve higher Quality of Service while minimize the cost. \\

We have identified two major challenges faced by cloud autoscaling systems. First, autoscaler need to be aware of the workload that system has to deal with. Second, autoscaler should  allocate right amount of resources to the system in cost effective manner while preserving Quality of Service. \\

There are two main approaches in cloud computing domain to address the first challenge. Depending on autoscaling approach, auto scaler would gain workload awareness in proactive or reactive manner. In reactive approach autoscaling decision would be triggered by predefined set of events. In contrast proactive autoscaling mechanisms forecast the workload ahead so the auto-scaler based can make decisions based on anticipated workload instead of waiting for a trigger. However major challenge in cloud workload prediction is to come up with solution that would perform with different workload patterns. For example a model that perform well on workloads with seasonal trends will not perform well with frequently fluctuating loads. \\

We opted proactive autoscaling over reactive in our solution because proactive mechanism supported by accurate prediction mechanism enable autoscaler to make more detailed decisions.
Reactive approach used in most PaaS autoscaler in our view is much simpler, but greatly reduce the solution space available when addressing the second (resource allocation) problem. In this paper we propose  workload prediction mechanism based on time series forecasting as well as machine learning techniques. Results has shown that ensemble method proposed outperform individual techniques in term of accuracy.\\

There are many research work conducted (discussed in section2) in relation to resource allocation problem as well. But almost all the available PaaS solutions are built on rule based scaling. For example in rule driven approach spin up decision will be taken when the average memory consumption of the cluster of virtual machines is over 75\%. These rule based mechanisms mostly rely on user defined threshold parameters. One of the major drawback in this rule based threshold-driven auto scaling is that the user is expected to be a domain expert and should be capable of setting up threshold values such as memory usage and CPU consumption for his application in order for configuring policies or rules to govern the scaling decisions \cite{modeldriven}. On the other hand, mapping application metrics such as response time and transactions per unit time to system level metrics such as CPU usage and disk IO rates is a research level problem, which an average user cannot comprehend. \\

In this paper we propose a greedy heuristic scaling algorithm considering both QoS as well as cost factors. In the algorithm we introduce the idea of ‘penalty factor’ for performance degradation, an idea inspired by penalties introduced in SLA of popular PaaS such as Google App Engine. The scaling algorithm evaluates all possibilities and selects the optimum resource configuration considering the lease cost and penalty due to performance degradation. This scaling mechanism mitigate the problem of comprehending a threshold values in rule based scaling. \\

Other than introducing a scaling algorithm to calculate  required resources We take a novel perspective in addressing this problem injecting pricing model awareness to our autoscaling solution as we see ignorance of the pricing model in scaling decisionmaking  is major drawback in PaaS auto scalers available. For a motivation example let us consider a typical application deployed on top of Amazon Web Service (AWS) PaaS. On a sudden fluctuation in the workload, a typical auto scaler would scale-out to spin up a new VM instance and when the workload is back to normal the auto-scaler would scale-in by blindly killing one of the VM instances which has already been paid for for an hour. Thus the customer has lost a 50 minutes utilization of the instance. Smart Killing feature we adapted to our solution from [Appscale] would apprehend the utilization of each VM instance and scale out instances only when their lease periods are about to expire. It would also save an extra cost by mitigating the requirement to spin up another instance on a sudden fluctuation of the workload within the paid hour. \\

In an attempt to implement our solution and demonstrate the effects of a PaaS auto-scaler, we target Apache Stratos PaaS; however, the techniques detailed here are extensible to other PaaS systems as well. Apache Stratos, an open source PaaS framework offering multi-tenancy and multi-cloud deployment capabilities by encapsulating the details to the level of reduced granularity and complexity of a PaaS. Stratos supports multiple IaaS providers, including AWS, OpenStack, GCE (Google Compute Engine) and Microsoft Azure\cite{website:stratos}. Stratos auto scaler is based on policy-driven  decisions, which performs workload prediction for a small time window (usually a few minutes) but does not utilize resource optimization approaches explicitly, thereby incurring unnecessary costs to the customer, such as overprovisioning of resources and naive scale down decisions. Apart from the typical characteristics of a PaaS auto scaler, Stratos offer other features such as a modular architecture allowing easy modifications, and the availability of a mock IaaS as a component for testing and evaluation, which would greatly assist any research in terms of monetary cost and implementation cost.\\

We evaluate inteliScaler by deploying  Apache Stratos on AWS Elastic Cloud Computing(EC2). We deploy the three-tier bidding benchmark RUBiS as the user application and experiment with various workload traces. Our results demonstrate that inteliScaler successfully scales the application in response to fluctuating workloads, without user intervention and without offline profiling. More importantly, we compare our solution with existing rule based triggers and show that inteliScaler is superior to such approaches.\\

